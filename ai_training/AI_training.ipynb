{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI-training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KMWqj3py5uHwEVD4A9Iio0-dnfDdyhQ7",
      "authorship_tag": "ABX9TyPDEJRwy+Vdz5woEqd4olEo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xTRam1/Cost-Effective-Reverse-Vending-Machine-Project/blob/main/AI_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzTjYpxoHSNo"
      },
      "source": [
        "## Using Modifiable Shell Script\n",
        "With this step, you can reproduce our results (96% percent accuracy TFlite model) or modify the parameters for your own project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo7mRE5VHoWS"
      },
      "source": [
        "# Cloning our GitHub repository\n",
        "!git clone \"https://github.com/xTRam1/Cost-Effective-Reverse-Vending-Machine-Project\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQpvJDBGHiu1"
      },
      "source": [
        "%cd ai_training\n",
        "!bash ai_train.sh # You can modify the parameters in this shell script"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwJzZ9EuImUq"
      },
      "source": [
        "# Look at your training summary from Tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUBoIy1PIBBQ"
      },
      "source": [
        "After training finishes, you must have two new files in your directory - one named \"model.tflite\" that contains the TensorflowLite model and \"labels.txt\" that containes a list of the labels in our training dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXFsHNHzIY57"
      },
      "source": [
        "## Training with code (possibly modifying it to your preferences)\n",
        "This allows for a better visualizing of the model training. It is also better as you can understand each and every component of the Deep Learning process instead of blindly running a line of command. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAuZgz-_K3bp"
      },
      "source": [
        "### Parameter and dataset initiations\n",
        "You can modify the parameters below to customize your Deep Learning training. The cell below prepares your data for training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnToyzACi81K"
      },
      "source": [
        "import tensorflow as tf \n",
        "import tensorflow_hub as hub\n",
        "import argparse\n",
        "import numpy\n",
        "import datetime\n",
        "\n",
        "# Parameters to modify\n",
        "lr = 0.001\n",
        "batch_size = 32\n",
        "do_finetuning = True\n",
        "epoch = 20\n",
        "# checkpoint_path = \"path/to/checkpoint/if/one/exists\"\n",
        "checkpoint_freq = 5\n",
        "\n",
        "data_root = \"path/to/your/dataset\"\n",
        "classifier_model = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
        "datagen_kwargs = dict(rescale=1./255, brightness_range=(0.7, 1.0), vertical_flip=True, horizontal_flip=True, validation_split=0.2) # Pre-processing methods\n",
        "img_shape = (224, 224)\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    data_root,\n",
        "    shuffle=True,\n",
        "    target_size=img_shape,\n",
        "    batch_size=batch_size,\n",
        "    subset='training'\n",
        ")\n",
        "valid_data = train_datagen.flow_from_directory(\n",
        "    data_root,\n",
        "    shuffle=True,\n",
        "    target_size=img_shape,\n",
        "    batch_size=batch_size,\n",
        "    subset='validation'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1peB2lGK7HI"
      },
      "source": [
        "### Model initiation\n",
        "Downloads the pre-trained tensorflow backbone and builds the model. The cell also specifies the loss function and the callback metrics to track during training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O745mjGLFetj"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    # Explicitly define the input shape so the model can be properly\n",
        "    # loaded by the TFLiteConverter\n",
        "    tf.keras.layers.InputLayer(input_shape=img_shape+(3,)),\n",
        "    # Pre-trained model from Tensorflow Hub \n",
        "    hub.KerasLayer(classifier_model, trainable=do_finetuning),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(train_data.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.build((None,)+img_shape+(3,))\n",
        "\n",
        "# If you want to use a previous checkpoint, uncomment the following line\n",
        "# model.load_weights(args.checkpoint_path)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=lr),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['acc'])\n",
        "model.summary()\n",
        "steps_per_epoch = train_data.samples // train_data.batch_size\n",
        "validation_steps = valid_data.samples // valid_data.batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o465I9DJZAG"
      },
      "source": [
        "# If you want to clear the prior logging data, run this cell\n",
        "!rm -rf logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01uO9HWcK_GU"
      },
      "source": [
        "### Training\n",
        "Below step trains your model and visualizes its training/validation metrics. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCjda68cFfbg"
      },
      "source": [
        "logdir = \"logs/\" + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "checkpoint_path = \"checkpoints/cp-{epoch:04d}.ckpt\"\n",
        "\n",
        "# Define the basic TensorBoard callback.\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq=5*batch_size)\n",
        "\n",
        "history = model.fit(train_data, epochs=epoch,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_data,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[cp_callback, tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grCvRKScqZ9T"
      },
      "source": [
        "# To see the logs after training, run this command\n",
        "%tensorboard --logdir logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hohB4QJLF_H"
      },
      "source": [
        "### Testing\n",
        "Test if your model works correctly before converting it into a TFlite model. \n",
        "This cell gives you the validation accuracy and the falsely classified images to diagnose your model and its training parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OKR7H6dItzD"
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "\n",
        "def get_class_string_from_index(index):\n",
        "   for class_string, class_index in valid_data.class_indices.items():\n",
        "      if class_index == index:\n",
        "         return class_string\n",
        "\n",
        "error_count = 0\n",
        "for i in range(valid_data.samples):\n",
        "    x, y = next(valid_data)\n",
        "    image = x[0, :, :, :]\n",
        "    true_index = numpy.argmax(y[0])\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Expand the validation image to (1, 224, 224, 3) before predicting the label\n",
        "    prediction_scores = model.predict(numpy.expand_dims(image, axis=0))\n",
        "    predicted_index = numpy.argmax(prediction_scores)\n",
        "\n",
        "    # Look at images that your model is failing to classify correcly to make the necessary adjustments to your model parameters\n",
        "    if predicted_index != true_index:  \n",
        "        error_count += 1\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        print(\"True label: \" + get_class_string_from_index(true_index))\n",
        "        print(\"Predicted label: \" + get_class_string_from_index(predicted_index))\n",
        "\n",
        "# Prints your model's performance for the validation dataset\n",
        "print('Validation accuracy is {}'.format((1.0 - (error_count / valid_data.samples)) * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVNHxmxPLI9L"
      },
      "source": [
        "### Saving your model and your label list\n",
        "After the above cell is executed, you must have two new files in your directory - one named \"model.tflite\" that contains the TensorflowLite model and \"labels.txt\" that containes a list of the labels in our training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8aXBl4bFjqN"
      },
      "source": [
        "# Converting model into TensorflowLite model\n",
        "saved_model_dir = \"path/to/save/your/model\"\n",
        "tf.saved_model.save(model, saved_model_dir)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Saving the model and label map into two seperate files for further use\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_data.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "    f.write(labels)\n",
        "\n",
        "# All that is left is to use this TFLite model in your Raspberry Pi 4. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEz7w_hILfIl"
      },
      "source": [
        "### Testing your TFLite model\n",
        "Belove cell tests your TFLite model's performance by printing the model's validation accuracy and by outputting the images which the model has failed classifying correctly. You must use the results of this step to identify any mistakes with your model and adjust the parameters accordingly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7l1ftc_NLuJ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "def set_input_tensor(interpreter, image):\n",
        "  tensor_index = interpreter.get_input_details()[0]['index']\n",
        "  input_tensor = interpreter.tensor(tensor_index)()[0]\n",
        "  input_tensor[:, :] = image\n",
        "\n",
        "def load_labels(path):\n",
        "    \"\"\"Loads the file path of the labels file.\"\"\"\n",
        "    with open(path, 'r') as f:\n",
        "        return {i: line.strip() for i, line in enumerate(f.readlines())}\n",
        "\n",
        "# Setting up the model and the labels\n",
        "labels = load_labels(\"labels.txt\")\n",
        "interpreter = tf.lite.Interpreter(\"model_finetune.tflite\")\n",
        "\n",
        "error_count = 0\n",
        "for _ in range(valid_data.samples):\n",
        "    interpreter.allocate_tensors()\n",
        "    _, height, width, _ = interpreter.get_input_details()[0]['shape']\n",
        "    x, y = next(valid_data)\n",
        "    image = x[0, :, :, :]\n",
        "    true_index = np.argmax(y[0])\n",
        "\n",
        "    top_k = 1\n",
        "    set_input_tensor(interpreter, image)\n",
        "    interpreter.invoke()\n",
        "    output_details = interpreter.get_output_details()[0]\n",
        "    output = np.squeeze(interpreter.get_tensor(output_details['index']))\n",
        "    ordered = np.argpartition(-output, top_k)\n",
        "    results = [(i, output[i]) for i in ordered[:top_k]]\n",
        "    label_id, prob = results[0]\n",
        "\n",
        "    if labels[true_index] != labels[label_id]:\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        print(\"True label: \" + labels[true_index] + \" Probability: \" + str(prob))\n",
        "        print(\"Predicted label: \" + labels[label_id])\n",
        "        error_count += 1\n",
        "print('Validation accuracy is {}'.format((1.0 - (error_count / valid_data.samples)) * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
