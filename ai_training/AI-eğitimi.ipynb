{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AI-eÄŸitimi.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1KMWqj3py5uHwEVD4A9Iio0-dnfDdyhQ7","authorship_tag":"ABX9TyObHXxAQ+2MUqzPZyDGt7HW"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"obsMAN5W40vp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609145408847,"user_tz":-180,"elapsed":678,"user":{"displayName":"Lutfu Eren Erdogan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgREIuzrZXB4tOrEYhHddHSx9DyvUHhvaPEBSRXvQ=s64","userId":"02490270727596142538"}},"outputId":"795d6d1f-f3ed-43ad-c43e-a3dd7576e6be"},"source":["%cd \"/content/drive/MyDrive/Reverse Vending Machine ----------------------------------------------------------------\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Reverse Vending Machine ----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xCY1YxxTPHuU"},"source":["!python3 ai.py --batch_size 32 --epoch 50 --lr 0.001 \\\n","    --data_root \"/content/drive/MyDrive/Reverse Vending Machine ----------------------------------------------------------------/dataset\" \\\n","    --save_dir \"/content/drive/MyDrive/Reverse Vending Machine ----------------------------------------------------------------\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nr4-sIRzRUVd"},"source":["%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zbYjQ-4ZPY5B"},"source":["%tensorboard --logdir logs/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GG8BaSRahQzL"},"source":["!python3 ai.py --batch_size 32 --epoch 10 --lr 0.001 \\\n","    --data_root \"/content/drive/MyDrive/Reverse Vending Machine/dataset\" \\\n","    --save_dir \"/content/drive/MyDrive/Reverse Vending Machine\" \\\n","    --do_finetuning \"True\" "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IGq01756im7K"},"source":["!python3 ai.py --batch_size 32 --epoch 10 --lr 0.01 \\\n","    --data_root \"/content/drive/MyDrive/Reverse Vending Machine/dataset\" \\\n","    --save_dir \"/content/drive/MyDrive/Reverse Vending Machine\" \\\n","    --do_finetuning \"False\" \\\n","    --continue_path \"/content/drive/MyDrive/Reverse Vending Machine\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qnToyzACi81K"},"source":["import tensorflow as tf \n","import tensorflow_hub as hub\n","import argparse\n","import numpy\n","import datetime\n","\n","lr = 0.001\n","batch_size = 32\n","do_finetuning = True\n","epoch = 20\n","\n","data_root = \"/content/drive/MyDrive/Reverse Vending Machine ----------------------------------------------------------------/dataset\"\n","classifier_model = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n","datagen_kwargs = dict(rescale=1./255, brightness_range=(0.7, 1.0), vertical_flip=True, horizontal_flip=True, validation_split=0.2) # Pre-processing methods\n","img_shape = (224, 224)\n","\n","train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n","train_data = train_datagen.flow_from_directory(\n","    data_root,\n","    shuffle=True,\n","    target_size=img_shape,\n","    batch_size=batch_size,\n","    subset='training'\n",")\n","valid_data = train_datagen.flow_from_directory(\n","    data_root,\n","    shuffle=True,\n","    target_size=img_shape,\n","    batch_size=batch_size,\n","    subset='validation'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RT1tpA7mhRD_"},"source":["# Raspberry pi ile son layer tuning lr = 0.01"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VVhsdRJshRVo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"18m0nKAdhRo1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x28gXVKg9ulK"},"source":["import tensorflow as tf \n","import tensorflow_hub as hub\n","import argparse\n","import numpy\n","import datetime\n","\n","lr = 0.001\n","batch_size = 32\n","do_finetuning = True\n","epoch = 20\n","\n","data_root = \"/content/drive/MyDrive/Reverse Vending Machine ----------------------------------------------------------------/dataset\"\n","classifier_model = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n","datagen_kwargs = dict(rescale=1./255, brightness_range=(0.7, 1.0), vertical_flip=True, horizontal_flip=True, validation_split=0.2) # Pre-processing methods\n","img_shape = (224, 224)\n","\n","train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n","train_data = train_datagen.flow_from_directory(\n","    data_root,\n","    shuffle=True,\n","    target_size=img_shape,\n","    batch_size=batch_size,\n","    subset='training'\n",")\n","valid_data = train_datagen.flow_from_directory(\n","    data_root,\n","    shuffle=True,\n","    target_size=img_shape,\n","    batch_size=batch_size,\n","    subset='validation'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O745mjGLFetj","executionInfo":{"status":"ok","timestamp":1609158738787,"user_tz":-180,"elapsed":61506,"user":{"displayName":"Lutfu Eren Erdogan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgREIuzrZXB4tOrEYhHddHSx9DyvUHhvaPEBSRXvQ=s64","userId":"02490270727596142538"}}},"source":["model = tf.keras.Sequential([\n","    # Explicitly define the input shape so the model can be properly\n","    # loaded by the TFLiteConverter\n","    tf.keras.layers.InputLayer(input_shape=img_shape+(3,)),\n","    # Pre-trained model from Tensorflow Hub \n","    hub.KerasLayer(classifier_model, trainable=do_finetuning),\n","    tf.keras.layers.Dropout(rate=0.5),\n","    tf.keras.layers.Dense(train_data.num_classes, activation='softmax')\n","])\n","\n","model.build((None,)+img_shape+(3,))\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(lr=lr),\n","        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","        metrics=['acc'])\n","\n","steps_per_epoch = train_data.samples // train_data.batch_size\n","validation_steps = valid_data.samples // valid_data.batch_size"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ldqfYzmGF--"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"woij5-vfUsQH"},"source":["%cd \"/content/drive/MyDrive/Reverse Vending Machine ----------------------------------------------------------------\"\n","!mkdir checkpoints"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zCjda68cFfbg"},"source":["# Dont forget to clear out prior loggin data by \"!rm -rf logs/image\"\n","logdir = \"logs/\" + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","checkpoint_path = \"/content/drive/MyDrive/Reverse Vending Machine ----------------------------------------------------------------/checkpoints\"\n","\n","# Define the basic TensorBoard callback.\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_path, \n","    verbose=1, \n","    save_weights_only=True,\n","    save_freq=5*batch_size)\n","\n","history = model.fit(train_data, epochs=epoch,\n","    steps_per_epoch=steps_per_epoch,\n","    validation_data=valid_data,\n","    validation_steps=validation_steps,\n","    callbacks=[cp_callback, tensorboard_callback])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wYCNwY_hYumK","executionInfo":{"status":"ok","timestamp":1609160022277,"user_tz":-180,"elapsed":60113,"user":{"displayName":"Lutfu Eren Erdogan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgREIuzrZXB4tOrEYhHddHSx9DyvUHhvaPEBSRXvQ=s64","userId":"02490270727596142538"}},"outputId":"324ae8c8-8a1a-4f94-c1a2-cdfa6ccb92d3"},"source":["latest = tf.train.latest_checkpoint(\"/content/drive/MyDrive/Reverse Vending Machine/\")\n","# Create a new model instance\n","model = tf.keras.Sequential([\n","    # Explicitly define the input shape so the model can be properly\n","    # loaded by the TFLiteConverter\n","    tf.keras.layers.InputLayer(input_shape=img_shape+(3,)),\n","    # Pre-trained model from Tensorflow Hub \n","    hub.KerasLayer(classifier_model, trainable=do_finetuning),\n","    tf.keras.layers.Dropout(rate=0.5),\n","    tf.keras.layers.Dense(train_data.num_classes, activation='softmax')\n","])\n","\n","# Load the previously saved weights\n","model.load_weights(latest)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8b935692b0>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"HXawwN6wqVI_"},"source":["%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"grCvRKScqZ9T"},"source":["# To see the logs after training, run this command\n","%tensorboard --logdir logs/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3OKR7H6dItzD"},"source":["import matplotlib.pylab as plt\n","def get_class_string_from_index(index):\n","   for class_string, class_index in valid_data.class_indices.items():\n","      if class_index == index:\n","         return class_string\n","\n","x, y = next(valid_data)\n","image = x[0, :, :, :]\n","true_index = numpy.argmax(y[0])\n","plt.imshow(image)\n","plt.axis('off')\n","plt.show()\n","\n","# Expand the validation image to (1, 224, 224, 3) before predicting the label\n","prediction_scores = model.predict(numpy.expand_dims(image, axis=0))\n","predicted_index = numpy.argmax(prediction_scores)\n","print(\"True label: \" + get_class_string_from_index(true_index))\n","print(\"Predicted label: \" + get_class_string_from_index(predicted_index))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A8aXBl4bFjqN","executionInfo":{"status":"ok","timestamp":1609160188956,"user_tz":-180,"elapsed":10767,"user":{"displayName":"Lutfu Eren Erdogan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgREIuzrZXB4tOrEYhHddHSx9DyvUHhvaPEBSRXvQ=s64","userId":"02490270727596142538"}},"outputId":"f4a8e25d-7737-4b90-f4c9-3729404ccee8"},"source":["# Converting model into TensorflowLite model\n","saved_model_dir = '/content/drive/MyDrive/Reverse Vending Machine ----------------------------------------------------------------/' # '[directory you want to save your model to]'\n","tf.saved_model.save(model, saved_model_dir)\n","\n","converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n","tflite_model = converter.convert()\n","\n","# Saving the model and label map into two seperate files for further use\n","with open('model_finetune.tflite', 'wb') as f:\n","    f.write(tflite_model)\n","\n","labels = '\\n'.join(sorted(train_data.class_indices.keys()))\n","\n","with open('labels.txt', 'w') as f:\n","    f.write(labels)\n","\n","# All that is left is to use this TFLite model in your Raspberry Pi 4. "],"execution_count":16,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/Reverse Vending Machine ----------------------------------------------------------------/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/Reverse Vending Machine ----------------------------------------------------------------/assets\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RDYLWjzJABa4","executionInfo":{"status":"ok","timestamp":1609053624858,"user_tz":-180,"elapsed":686,"user":{"displayName":"Lutfu Eren Erdogan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgREIuzrZXB4tOrEYhHddHSx9DyvUHhvaPEBSRXvQ=s64","userId":"02490270727596142538"}},"outputId":"588eb2d5-54d4-42cc-b6f7-85d1b230a109"},"source":["%cd '/content/drive/MyDrive/Reverse Vending Machine ----------------------------------------------------------------/deneme'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Reverse Vending Machine ----------------------------------------------------------------/deneme\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F7l1ftc_NLuJ"},"source":["import numpy as np\n","import matplotlib.pylab as plt\n","\n","def set_input_tensor(interpreter, image):\n","  tensor_index = interpreter.get_input_details()[0]['index']\n","  input_tensor = interpreter.tensor(tensor_index)()[0]\n","  input_tensor[:, :] = image\n","\n","def load_labels(path):\n","    \"\"\"Loads the file path of the labels file.\"\"\"\n","    with open(path, 'r') as f:\n","        return {i: line.strip() for i, line in enumerate(f.readlines())}\n","\n","# Setting up the model and the labels\n","labels = load_labels(\"labels.txt\")\n","interpreter = tf.lite.Interpreter(\"model_finetune.tflite\")\n","\n","error_count = 0\n","for _ in range(valid_data.samples):\n","    interpreter.allocate_tensors()\n","    _, height, width, _ = interpreter.get_input_details()[0]['shape']\n","    x, y = next(valid_data)\n","    image = x[0, :, :, :]\n","    true_index = np.argmax(y[0])\n","\n","    top_k = 1\n","    set_input_tensor(interpreter, image)\n","    interpreter.invoke()\n","    output_details = interpreter.get_output_details()[0]\n","    output = np.squeeze(interpreter.get_tensor(output_details['index']))\n","    ordered = np.argpartition(-output, top_k)\n","    results = [(i, output[i]) for i in ordered[:top_k]]\n","    label_id, prob = results[0]\n","\n","    if labels[true_index] != labels[label_id]:\n","        plt.imshow(image)\n","        plt.axis('off')\n","        plt.show()\n","        print(\"True label: \" + labels[true_index] + \" Probability: \" + str(prob))\n","        print(\"Predicted label: \" + labels[label_id])\n","        error_count += 1\n","print('Validation accuracy is {}'.format((1.0 - (error_count / valid_data.samples)) * 100.0))"],"execution_count":null,"outputs":[]}]}